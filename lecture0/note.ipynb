{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic: Search\n",
    "### Terminologies:\n",
    "+ Agent: entity that perceives its environment and acts upon that environment\n",
    "+ State: a configuration of the agent and its environment\n",
    "+ Initial state: 1st step of the agent\n",
    "+ Actions: choices can be made in a state => ACTION(s) returns the set of actions that can be executed in state s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition model\n",
    "a description of what state results from performing any applicable action in any state\n",
    "\n",
    "=> RESULT(s,a) returns the state resulting from performing action a in state s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State space\n",
    "\n",
    "The set of all states reachable from the initial state by any sequence of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal test\n",
    "\n",
    "way to determine whether a given state is a goal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path cost\n",
    "\n",
    "numerical cost associated with a given path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Problems\n",
    "+ Initial state\n",
    "+ Actions\n",
    "+ Transition model\n",
    "+ Goal test\n",
    "+ Path cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: a sequence of actions that leads from the initial state to a goal state\n",
    "\n",
    "#### Optimal solution: a solution that has the lowest path cost among all solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node\n",
    "A data structure that keeps track of:\n",
    "+ a state\n",
    "+ a parent (node that generated this node)\n",
    "+ an action (action applied to parent to get node)\n",
    "+ a path cost (from initial state to node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "+ Start with a frontier that contains the initial state.\n",
    "+ Repeat:\n",
    "    + If the frontiers is empty, then no solution.\n",
    "    + Remove a node from the frontier.\n",
    "    + If node contains goal state, return the solution.\n",
    "    + Expand node, add resulting nodes to the frontiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised Approach\n",
    "+ Start with a frontier that contains the initial state\n",
    "+ Start with an empty explored set\n",
    "+ Repeat:\n",
    "    + If the frontiers is empty, then no solution.\n",
    "    + Remove a node from the frontier.\n",
    "    + If node contains goal state, return the solution.\n",
    "    + Add the node to the explored set.\n",
    "    + Expand node, add resulting nodes to the frontiers if they aren't already in the frontier or the explored set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth-first search\n",
    "search algorithm that always expands the deepest node in the frontier\n",
    "### stack\n",
    "last-in first-out data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth-first search\n",
    "search algorithm that always expands the shallowest node in the frontier\n",
    "#### queue\n",
    "first-in first-out data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninformed Search\n",
    "search strategy that uses no problem-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informed search\n",
    "search strategy that uses problem-specific knowledge to find solutions more efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy best-first search\n",
    "search algorithm that expands the node that is closest to the goal, as estimated by a heuristic function <i>h(n)<i>\n",
    "=> Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* search\n",
    "search algorithm that expands node with lowest value of g(n) + h(n)\n",
    "\n",
    "g(n) = cost to reach node\n",
    "h(n) = estimated cost to goal\n",
    "\n",
    "optimal if\n",
    "- h(n) is admissible (never overestimates the true cost), and\n",
    "- h(n) is consistent (for every node n and successor n' with step cost c, h(n)<=h(n')+c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search\n",
    "Minimax\n",
    "+ Max (X) aims to maximize score.\n",
    "+ Min (O) aims to minimize socre.\n",
    "\n",
    "#### Game\n",
    "+ S(0): initial state\n",
    "+ Player(s): returns with player to move in state <i>s</i>\n",
    "+ Actions(s): returns legal moves in state <i>s</i>\n",
    "+ Result(s,a): returns state after action <i>a</i> taken in state <i>s</i>\n",
    "+ Terminal(s): checks if state <i>s</i> is a terminal state\n",
    "+ Utility(s): final numerical  value for terminal state <i>s</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimax algorithm\n",
    "+ Given a state <i>s</i>\n",
    "    + MAX picks action <i>a</i> in Actions(s) that produces highest value of Min-Value(Result(s,a))\n",
    "    + MIN picks action <i>a</i> in Actions(s) that produces smallest value of Max-Value(Result(s,a))\n",
    "\n",
    "function Max-Value(state):<br>\n",
    "     if Terminal(state):<br>\n",
    "        return Utility(state)<br>\n",
    "    v = - infinity<br>\n",
    "    for action in Actions(state):<br>\n",
    "        v = Max(v, Min-Value(Result(state, action)))<br>\n",
    "    return v<br>\n",
    "\n",
    "function Min-Value(state):<br>\n",
    "     if Terminal(state):<br>\n",
    "        return Utility(state)<br>\n",
    "    v = infinity<br>\n",
    "    for action in Actions(state):<br>\n",
    "        v = Min(v, Max-Value(Result(state, action)))<br>\n",
    "    return v<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "Alpha-Beta Pruning\n",
    "Depth-Limited Minimax + evaluation function (function that estimates the expected utility of the game from a given state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
